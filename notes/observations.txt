Old tool
-------------
- Adding one more level of terms (i.e, next <x,y,z>) to list-find does not terminate after 18 min.
- Similar phenomenon with lseg-list-keys when next is added, even to just build level 1 terms. Does not terminate.
- lesg-keys does not terminate at all with any variation, including a minimal grammar that only has the elements necessary for the desired lemma.
- slist-find requires extra instantiation beyond what is expected to be able to prove the desired lemma. This is done by manual intervention at the moment. The idea is that after a point we will give up and increase the depth of instantiation from 0 to 1 (not implemented in the tool at the moment), at which point the instance will go through.
- Adding (next x) and (next y) to the grammar in slseg-nil-slist makes it take a lot more time
- lseg-nil-length needs a severely restricted grammar to go through. Small extensions do not terminate in reasonable time or trigger errors. 


New tool
------------
- tests/lseg-next.py: currently goes through, but bug arises when removing nxt(nil) = nil axiom --- solved
- tests/cyclic-rev.py: currently does not go through. grammar can be restricted likely 
- tests/lseg-list.py: when adding (nxt x) to grammar, lemma is reproposed --- solved
- tests/dlseg-prev.py: running forever
- tests/lseg-list-keys.py: ran for 35 mins, only proposed one lemma involving sets
- tests/bst-minimal.py: sygus (fairly quickly) returns unknown, meaning grammar is exhausted


Things to talk about the tool in the paper:
--------------------
- CVC4Sy does not support uninterpreted sorts, Z3 does not support subsorting. Our tool is therefore notrivial and not reducible to existing tools.
- Universal model generation. Made possible because queries are quantifier-free on the foreground sort, so we can extract finite models.
- Finite model extraction is determined by particular proof attempt. That makes the algorithm something that can adapt over time, do several retries.
- Instantiations are determined by grammar. That's a nice bit of complexity and shows that the proof method is goal driven as well as grammar-driven (like aarti's paper)
- Sensitivity of results to changes in grammar. Obvious because cvc4sy likely does enumerative synthesis.
- Experiments with putting in lemmas discovered in earlier examples -- shows reusability. Many problems end up fiding true lemmas that are maybe unnecessary for that particular example, but could be
useful for others.-- TODO: find a concrete example where this happens.
- Call the tool FOSILS. Say it is one of the first of its kind (aarti's is perhaps another) that does multiple sorts and datastructures (here we may truly be the first). Make a big deal about it as something people could maybe build verification procedures.
- 




TODO Future:
- Shift to cvc4sy python api if that would work better/be cleaner code
- Recdefs with bindings instead of rswitch
- BitVec encoding for fgsort
- Simplify (dovetail various combinations)
- cvc4 flags (ask andrew and then dovetail various combinations)
- Serious logging infrastructure
- Grammar sampler + lemsynth engine (much later)
- 
