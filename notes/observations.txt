----------------------------------------
Old tool
----------------------------------------

Things to talk about the tool in the paper:
- CVC4Sy does not support uninterpreted sorts, Z3 does not support subsorting. Our tool is therefore notrivial and not reducible to existing tools.
- Sensitivity of results to changes in grammar. Obvious because cvc4sy likely does enumerative synthesis.
- Experiments with putting in lemmas discovered in earlier examples -- shows reusability. Many problems end up fiding true lemmas that are maybe unnecessary for that particular example, but could be
useful for others.-- TODO: find a concrete example where this happens.
- 



TODO Future:
- Simplify translating to cvc4 format and then back again when z3 is used
- Recdefs with bindings instead of rswitch
- BitVec encoding for fgsort
- Serious logging infrastructure
- Grammar sampler + lemsynth engine (much later)
- 


--------------------------------------
New tool
---------------------------------------

TODO:
- ensure solver on master runs in all modes without any frills: all counterexamples, no type2 counterexamples, and no counterexamples at all (i.e, streaming with cvc4sy). The first two modes should run with both minisy and cvc4sy.
- clean up tests/ folder to only have a minimal set of tests for the tool
- clean up old_tool folder by salvaging any examples that are not included in the current benchmark suite, and delete everything else
- clean up counterexample-tests/ and counterexample_tests/ folders by adding them to the main test suite
- Update README and requirements.txt (should include matplotlib etc for plotting code)
- log all results for the main tool as well as adt and slcomp benchmarks in google drive.
- experiment with synthetic benchmarks with all counterexamples but synth engine cvc4sy
- experiment to determine how many examples actually have dependent lemmas. Evaluate by switching off previous valid lemmas when proving a new one.
- generalise the type2 counterexample generation to arbitrary recdefs with positive recursion (rather than a fixed list)
- debug reproposal





--------------------------------------
Observations from normalize-garmmars (archived)
---------------------------------------


Old tool
-------------
- Adding one more level of terms (i.e, next <x,y,z>) to list-find does not terminate after 18 min.
- Similar phenomenon with lseg-list-keys when next is added, even to just build level 1 terms. Does not terminate.
- lesg-keys does not terminate at all with any variation, including a minimal grammar that only has the elements necessary for the desired lemma.
- slist-find requires extra instantiation beyond what is expected to be able to prove the desired lemma. This is done by manual intervention at the moment. The idea is that after a point we will give up and increase the depth of instantiation from 0 to 1 (not implemented in the tool at the moment), at which point the instance will go through.
- Adding (next x) and (next y) to the grammar in slseg-nil-slist makes it take a lot more time
- lseg-nil-length needs a severely restricted grammar to go through. Small extensions do not terminate in reasonable time or trigger errors. 


New tool
------------
- tests/lseg-next.py: currently goes through, but bug arises when removing nxt(nil) = nil axiom --- solved
- tests/cyclic-rev.py: currently does not go through. grammar can be restricted likely 
- tests/lseg-list.py: when adding (nxt x) to grammar, lemma is reproposed --- solved
- tests/dlseg-prev.py: running forever
- tests/lseg-list-keys.py: ran for 35 mins, only proposed one lemma involving sets
- tests/bst-minimal.py: sygus (fairly quickly) returns unknown, meaning grammar is exhausted


Things to talk about the tool in the paper:
--------------------
- CVC4Sy does not support uninterpreted sorts, Z3 does not support subsorting. Our tool is therefore notrivial and not reducible to existing tools.
- Universal model generation. Made possible because queries are quantifier-free on the foreground sort, so we can extract finite models.
- Finite model extraction is determined by particular proof attempt. That makes the algorithm something that can adapt over time, do several retries.
- Instantiations are determined by grammar. That's a nice bit of complexity and shows that the proof method is goal driven as well as grammar-driven (like aarti's paper)
- Sensitivity of results to changes in grammar. Obvious because cvc4sy likely does enumerative synthesis.
- Experiments with putting in lemmas discovered in earlier examples -- shows reusability. Many problems end up fiding true lemmas that are maybe unnecessary for that particular example, but could be
useful for others.-- TODO: find a concrete example where this happens.
- Call the tool FOSILS. Say it is one of the first of its kind (aarti's is perhaps another) that does multiple sorts and datastructures (here we may truly be the first). Make a big deal about it as something people could maybe build verification procedures.
- 




TODO Future:
- Shift to cvc4sy python api if that would work better/be cleaner code
- Recdefs with bindings instead of rswitch
- BitVec encoding for fgsort
- Simplify (dovetail various combinations)
- cvc4 flags (ask andrew and then dovetail various combinations)
- Serious logging infrastructure
- Grammar sampler + lemsynth engine (much later)
- 
